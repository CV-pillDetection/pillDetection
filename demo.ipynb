{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1-D8tUFq3r2I9HrajG3GArGRXl55L_vAP",
     "timestamp": 1763646841136
    },
    {
     "file_id": "1vXyWdDbXQ8i80e2yZiY3SD2RPB4bQy8n",
     "timestamp": 1763496063297
    }
   ],
   "gpuType": "T4",
   "machine_shape": "hm"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "e8d187feb4914a6ab3c7aa0f0d7d6fec": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8bc165a7d7b949caa648de43e67d7fae",
       "IPY_MODEL_3b5da4835e914c669b9fd251aa410560",
       "IPY_MODEL_ba40a97b41564d3da5ba8eea03cf7e2d"
      ],
      "layout": "IPY_MODEL_320855a8034f43389b3135eac6afed1c"
     }
    },
    "8bc165a7d7b949caa648de43e67d7fae": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c5ec52405fa849f79af89a3b689f965e",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_2e56a2ed919a4a7d85e8a795b6566cbe",
      "value": "Ïù¥ÎØ∏ÏßÄ‚ÄáÏ≤òÎ¶¨‚ÄáÏ§ë:‚Äá100%"
     }
    },
    "3b5da4835e914c669b9fd251aa410560": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f6caf23253044f5aa80519a50ad18d27",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2f7bcf180e9646a28f774d380d9d08a8",
      "value": 10
     }
    },
    "ba40a97b41564d3da5ba8eea03cf7e2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_34432c8a3f524a49b43eff0dcc8b3629",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_408ac65e3f2d421d858823d8b7a113c5",
      "value": "‚Äá10/10‚Äá[00:43&lt;00:00,‚Äá‚Äá4.44s/it]"
     }
    },
    "320855a8034f43389b3135eac6afed1c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5ec52405fa849f79af89a3b689f965e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e56a2ed919a4a7d85e8a795b6566cbe": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f6caf23253044f5aa80519a50ad18d27": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2f7bcf180e9646a28f774d380d9d08a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "34432c8a3f524a49b43eff0dcc8b3629": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "408ac65e3f2d421d858823d8b7a113c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1Ô∏è‚É£ GPU ÌôïÏù∏"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T01:45:53.588260Z",
     "start_time": "2025-12-12T01:45:53.582503Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "print(f\"CUDA ÏÇ¨Ïö© Í∞ÄÎä•: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Î©îÎ™®Î¶¨: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"GPUÎ•º ÏÇ¨Ïö©Ìï† Ïàò ÏóÜÏäµÎãàÎã§\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA ÏÇ¨Ïö© Í∞ÄÎä•: False\n",
      "GPUÎ•º ÏÇ¨Ïö©Ìï† Ïàò ÏóÜÏäµÎãàÎã§\n"
     ]
    }
   ],
   "execution_count": 89
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2Ô∏è‚É£ Google Drive Ïó∞Îèô"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T01:45:53.624974Z",
     "start_time": "2025-12-12T01:45:53.620668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ],
   "outputs": [],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T01:45:53.635789Z",
     "start_time": "2025-12-12T01:45:53.631734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from tqdm.notebook import tqdm\n",
    "\n",
    "# DRIVE_BASE = \"/content/drive/MyDrive\"\n",
    "# YOLO_WEIGHTS = f\"/content/drive/MyDrive/Final Output/weights/best.pt\"\n",
    "# TEST_IMAGES_DIR = f\"/content/drive/MyDrive/Final Output/K-000250-000573-002483-006192_0_2_0_2_70_000_200.png\"\n",
    "# IMAGE_DIR = \"/content/drive/MyDrive/setpills/selected_imgs\"\n",
    "# OUTPUT_CSV = \"/content/drive/MyDrive/pill_matching_results.csv\"\n",
    "# OUTPUT_DIR = f\"/content/drive/MyDrive/Combined_output\"\n",
    "# SHAPE_COLOR_MODEL = '/content/drive/MyDrive/Final Output/pill_shape_color_resnet50_improved_best_shape.pth'\n",
    "#\n",
    "# print(f\"Drive ÎßàÏö¥Ìä∏ ÏôÑÎ£å\")\n",
    "# print(f\"YOLO Í∞ÄÏ§ëÏπò: {YOLO_WEIGHTS}\")\n",
    "# print(f\"ÌÖåÏä§Ìä∏ Ïù¥ÎØ∏ÏßÄ: {TEST_IMAGES_DIR}\")\n",
    "# print(f\"Í≤∞Í≥º Ï†ÄÏû•: {OUTPUT_DIR}\")"
   ],
   "outputs": [],
   "execution_count": 91
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T01:45:53.649728Z",
     "start_time": "2025-12-12T01:45:53.643514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "ROOT = Path().resolve()\n",
    "\n",
    "YOLO_WEIGHTS = ROOT / \"weights\" / \"best.pt\"\n",
    "SHAPE_COLOR_MODEL = ROOT / \"weights\" / \"pill_shape_color_resnet50_improved_best_shape.pth\"\n",
    "\n",
    "IMAGE_DIR = ROOT / \"images\"\n",
    "OUTPUT_CSV = ROOT / \"pill_matching_results.csv\"\n",
    "\n",
    "TEST_IMAGES_DIR = ROOT / \"images\" / \"K-000250-000573-002483-006192_0_2_0_2_70_000_200.png\"\n",
    "OUTPUT_DIR = ROOT / \"output\"\n",
    "\n",
    "print(\"Î°úÏª¨ Í≤ΩÎ°ú ÏÑ∏ÌåÖ ÏôÑÎ£å\")\n",
    "print(f\"YOLO Í∞ÄÏ§ëÏπò: {YOLO_WEIGHTS}\")\n",
    "print(f\"ÌÖåÏä§Ìä∏ Ïù¥ÎØ∏ÏßÄ: {TEST_IMAGES_DIR}\")\n",
    "print(f\"Í≤∞Í≥º Ï†ÄÏû•: {OUTPUT_DIR}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Î°úÏª¨ Í≤ΩÎ°ú ÏÑ∏ÌåÖ ÏôÑÎ£å\n",
      "YOLO Í∞ÄÏ§ëÏπò: C:\\Users\\yooni\\PycharmProjects\\pillDetection\\weights\\best.pt\n",
      "ÌÖåÏä§Ìä∏ Ïù¥ÎØ∏ÏßÄ: C:\\Users\\yooni\\PycharmProjects\\pillDetection\\images\\K-000250-000573-002483-006192_0_2_0_2_70_000_200.png\n",
      "Í≤∞Í≥º Ï†ÄÏû•: C:\\Users\\yooni\\PycharmProjects\\pillDetection\\output\n"
     ]
    }
   ],
   "execution_count": 92
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3Ô∏è‚É£ ÎùºÏù¥Î∏åÎü¨Î¶¨ ÏÑ§Ïπò"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T01:45:53.667290Z",
     "start_time": "2025-12-12T01:45:53.663148Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# !pip install ultralytics easyocr google-cloud-vision -q\n",
    "# print(\"ÎùºÏù¥Î∏åÎü¨Î¶¨ ÏÑ§Ïπò ÏôÑÎ£å\")"
   ],
   "outputs": [],
   "execution_count": 93
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4Ô∏è‚É£ Import"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T01:45:53.702809Z",
     "start_time": "2025-12-12T01:45:53.696940Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from dataclasses import dataclass\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from difflib import SequenceMatcher\n",
    "from ultralytics import YOLO\n",
    "import easyocr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image, ImageOps\n",
    "import base64\n",
    "import requests\n",
    "import random\n",
    "\n",
    "print(\"Import ÏôÑÎ£å\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import ÏôÑÎ£å\n"
     ]
    }
   ],
   "execution_count": 94
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5Ô∏è‚É£ ÌååÏù¥ÌîÑÎùºÏù∏ ÌÅ¥ÎûòÏä§ Ï†ïÏùò"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T01:45:53.723994Z",
     "start_time": "2025-12-12T01:45:53.717523Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PadToSquare:\n",
    "    def __call__(self, img):\n",
    "        w, h = img.size\n",
    "        max_wh = max(w, h)\n",
    "        padding = ((max_wh - w) // 2, (max_wh - h) // 2,\n",
    "                   (max_wh - w + 1) // 2, (max_wh - h + 1) // 2)\n",
    "        return ImageOps.expand(img, padding, fill=0)"
   ],
   "outputs": [],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T01:45:53.738829Z",
     "start_time": "2025-12-12T01:45:53.731834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GoogleVisionOCRWithApiKey:\n",
    "    def __init__(self, api_key: str):\n",
    "        self.api_key = api_key\n",
    "        self.endpoint = f\"https://vision.googleapis.com/v1/images:annotate?key={self.api_key}\"\n",
    "\n",
    "    def read_single_image(self, image_bgr: np.ndarray):\n",
    "        # BGR -> RGB -> JPG Ïù∏ÏΩîÎî©\n",
    "        img_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "        ok, buf = cv2.imencode(\".jpg\", img_rgb)\n",
    "        if not ok:\n",
    "            return None, 0.0\n",
    "\n",
    "        img_base64 = base64.b64encode(buf.tobytes()).decode(\"utf-8\")\n",
    "\n",
    "        payload = {\n",
    "            \"requests\": [\n",
    "                {\n",
    "                    \"image\": {\"content\": img_base64},\n",
    "                    \"features\": [{\"type\": \"TEXT_DETECTION\"}],\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            resp = requests.post(self.endpoint, json=payload, timeout=5)\n",
    "        except Exception as e:\n",
    "            print(f\"Vision API ÏöîÏ≤≠ Ïã§Ìå®: {e}\")\n",
    "            return None, 0.0\n",
    "\n",
    "        if resp.status_code != 200:\n",
    "            print(\"Vision API Ïò§Î•ò:\", resp.status_code, resp.text[:200])\n",
    "            return None, 0.0\n",
    "\n",
    "        data = resp.json()\n",
    "        try:\n",
    "            annotations = data[\"responses\"][0].get(\"textAnnotations\", [])\n",
    "        except (KeyError, IndexError):\n",
    "            return None, 0.0\n",
    "\n",
    "        if not annotations:\n",
    "            return None, 0.0\n",
    "\n",
    "        full_text = annotations[0].get(\"description\", \"\")\n",
    "\n",
    "        # ÏïΩ Í∞ÅÏù∏Ïö©: ÏòÅÎ¨∏ + Ïà´ÏûêÎßå, Í≥µÎ∞±ÏùÄ ÌïòÎÇòÎ°ú Ï†ïÎ¶¨\n",
    "        filtered = []\n",
    "        for ch in full_text:\n",
    "            if ch.isalnum():\n",
    "                filtered.append(ch.upper())\n",
    "            elif ch.isspace():\n",
    "                filtered.append(\" \")\n",
    "        cleaned = \" \".join(\"\".join(filtered).split())\n",
    "\n",
    "        if not cleaned:\n",
    "            return None, 0.0\n",
    "\n",
    "        return cleaned, 1.0\n"
   ],
   "outputs": [],
   "execution_count": 96
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T01:45:53.755680Z",
     "start_time": "2025-12-12T01:45:53.744959Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PillScoreLineDetector:\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def _preprocess_for_scoreline(self, image: np.ndarray) -> np.ndarray:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        denoised = cv2.bilateralFilter(gray, 9, 75, 75)\n",
    "\n",
    "        min_val, max_val = np.percentile(denoised, [2, 98])\n",
    "\n",
    "        stretched = np.clip((denoised - min_val) * 255.0 / (max_val - min_val), 0, 255).astype(np.uint8)\n",
    "\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "        gradient = cv2.morphologyEx(stretched, cv2.MORPH_GRADIENT, kernel)\n",
    "\n",
    "        enhanced = cv2.addWeighted(stretched, 0.8, gradient, 0.2, 0)\n",
    "\n",
    "        return enhanced\n",
    "\n",
    "    def _line_passes_center(self, x1: int, y1: int, x2: int, y2: int,\n",
    "                           cx: int, cy: int, tolerance: int = 15) -> bool:\n",
    "        numerator = abs((y2-y1)*cx - (x2-x1)*cy + x2*y1 - y2*x1)\n",
    "        denominator = np.sqrt((y2-y1)**2 + (x2-x1)**2)\n",
    "\n",
    "        if denominator == 0:\n",
    "            return False\n",
    "\n",
    "        distance = numerator / denominator\n",
    "        return distance <= tolerance\n",
    "\n",
    "    def extract_score_lines(self, image: np.ndarray) -> Tuple[int, str]:\n",
    "        try:\n",
    "            enhanced = self._preprocess_for_scoreline(image)\n",
    "\n",
    "            blurred = cv2.GaussianBlur(enhanced, (3, 3), 0)\n",
    "            edges = cv2.Canny(blurred, 30, 100, apertureSize=3)\n",
    "\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "            edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "            min_len = int(min(image.shape[:2]) * 0.6)\n",
    "            lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=80,\n",
    "                                    minLineLength=min_len,\n",
    "                                    maxLineGap=10)\n",
    "\n",
    "            if lines is None:\n",
    "                return 0, 'none'\n",
    "\n",
    "            h, w = image.shape[:2]\n",
    "            center_x, center_y = w // 2, h // 2\n",
    "\n",
    "            horizontal_lines = []\n",
    "            vertical_lines = []\n",
    "\n",
    "            for line in lines:\n",
    "                x1, y1, x2, y2 = line[0]\n",
    "\n",
    "                length = np.sqrt((x2-x1)**2 + (y2-y1)**2)\n",
    "                angle = np.abs(np.arctan2(y2-y1, x2-x1) * 180 / np.pi)\n",
    "\n",
    "                if not self._line_passes_center(x1, y1, x2, y2, center_x, center_y, tolerance=20):\n",
    "                    continue\n",
    "\n",
    "                if length < min(h, w) * 0.6:\n",
    "                    continue\n",
    "\n",
    "                if angle <= 20 or angle >= 160: # ÏàòÌèâ Î≤îÏúÑ\n",
    "                    horizontal_lines.append({'length': length, 'angle': angle, 'coords': (x1, y1, x2, y2)})\n",
    "                elif 70 <= angle <= 110: # ÏàòÏßÅ Î≤îÏúÑ\n",
    "                    vertical_lines.append({'length': length, 'angle': angle, 'coords': (x1, y1, x2, y2)})\n",
    "\n",
    "            h_count = min(len(horizontal_lines), 1)\n",
    "            v_count = min(len(vertical_lines), 1)\n",
    "            total_count = h_count + v_count\n",
    "\n",
    "            if total_count == 0:\n",
    "                return 0, 'none'\n",
    "            elif total_count == 1:\n",
    "                return 1, '-'\n",
    "            else:\n",
    "                return 2, '+'\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Î∂ÑÌï†ÏÑ† Í≤ÄÏ∂ú Ï§ë Ïò§Î•ò: {e}\")\n",
    "            return 0, 'none'\n",
    "\n",
    "    def detect_from_bboxes(self,\n",
    "                          original_image: np.ndarray,\n",
    "                          bboxes: List[List[int]],\n",
    "                          image_name: str) -> List[Dict]:\n",
    "\n",
    "        results = []\n",
    "\n",
    "        for bbox_id, bbox in enumerate(bboxes):\n",
    "            if len(bbox) == 4:\n",
    "                x1, y1, x2, y2 = bbox\n",
    "            else:\n",
    "                raise ValueError(\"ÏûòÎ™ªÎêú bbox ÌòïÏãù\")\n",
    "\n",
    "            cropped = original_image[y1:y2, x1:x2]\n",
    "\n",
    "            line_count, line_type = self.extract_score_lines(cropped)\n",
    "\n",
    "            result = {\n",
    "                'image_name': image_name,\n",
    "                'bbox_id': bbox_id,\n",
    "                'bbox': bbox,\n",
    "                'score_line_count': line_count,\n",
    "                'score_line_type': line_type,\n",
    "            }\n",
    "\n",
    "            results.append(result)\n",
    "\n",
    "        return results\n"
   ],
   "outputs": [],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T01:45:53.795053Z",
     "start_time": "2025-12-12T01:45:53.763037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import dataclasses\n",
    "from typing import Tuple, List, Dict\n",
    "import numpy as np\n",
    "\n",
    "@dataclass\n",
    "class PillDetection:\n",
    "    bbox: Tuple[int, int, int, int]\n",
    "    confidence: float\n",
    "    crop_image: np.ndarray\n",
    "\n",
    "@dataclass\n",
    "class PillAnalysisResult:\n",
    "    detection_count: int\n",
    "    pills: List[Dict]\n",
    "\n",
    "class PadToSquare:\n",
    "    def __call__(self, img):\n",
    "        w, h = img.size\n",
    "        max_wh = max(w, h)\n",
    "        padding = ((max_wh - w)//2, (max_wh - h)//2,\n",
    "                   (max_wh - w+1)//2, (max_wh - h+1)//2)\n",
    "        return ImageOps.expand(img, padding, fill=255)\n",
    "\n",
    "\n",
    "class ColorNormalizer:\n",
    "    def __init__(self):\n",
    "        self.mean = [0.5, 0.5, 0.5]\n",
    "        self.std = [0.5, 0.5, 0.5]\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        for t, m, s in zip(tensor, self.mean, self.std):\n",
    "            t.sub_(m).div_(s)\n",
    "        return tensor\n",
    "\n",
    "\n",
    "class ShapeColorResNet_v1(nn.Module):\n",
    "    def __init__(self, num_shapes, num_colors):\n",
    "        super(ShapeColorResNet_v1, self).__init__()\n",
    "        resnet = models.resnet50(weights='IMAGENET1K_V1')\n",
    "\n",
    "        for param in resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.features = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        num_ftrs = resnet.fc.in_features\n",
    "\n",
    "        self.fc_shape = nn.Linear(num_ftrs, num_shapes)\n",
    "        self.fc_color = nn.Linear(num_ftrs, num_colors)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        shape_out = self.fc_shape(x)\n",
    "        color_out = self.fc_color(x)\n",
    "        return shape_out, color_out\n",
    "\n",
    "\n",
    "class ShapeColorResNet_v2(nn.Module):\n",
    "    def __init__(self, num_shapes, num_colors):\n",
    "        super(ShapeColorResNet_v2, self).__init__()\n",
    "        resnet = models.resnet50(weights='IMAGENET1K_V1')\n",
    "\n",
    "        for param in resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.features = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        num_ftrs = resnet.fc.in_features\n",
    "\n",
    "        self.fc_shape = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(num_ftrs, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, num_shapes)\n",
    "        )\n",
    "\n",
    "        self.fc_color = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(num_ftrs, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, num_colors)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        shape_out = self.fc_shape(x)\n",
    "        color_out = self.fc_color(x)\n",
    "        return shape_out, color_out\n",
    "\n",
    "\n",
    "class ImprovedColorAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.color_ranges = {\n",
    "            'Ìù∞ÏÉâ': [(0, 0, 200), (180, 30, 255)],\n",
    "            'ÎÖ∏Îûë': [(20, 100, 100), (30, 255, 255)],\n",
    "            'Ïó∞Îëê': [(30, 50, 100), (60, 255, 255)],\n",
    "            'Ï¥àÎ°ù': [(60, 100, 50), (80, 255, 255)],\n",
    "            'ÎØºÌä∏': [(80, 30, 150), (100, 150, 255)],\n",
    "            'ÌååÎûë': [(100, 100, 50), (130, 255, 255)],\n",
    "            'Î≥¥Îùº': [(130, 50, 50), (160, 255, 255)],\n",
    "            'ÌïëÌÅ¨': [(160, 50, 150), (180, 255, 255)],\n",
    "            'Îπ®Í∞ï1': [(0, 100, 100), (10, 255, 255)],\n",
    "            'Îπ®Í∞ï2': [(170, 100, 100), (180, 255, 255)],\n",
    "            'Ï£ºÌô©': [(10, 100, 100), (20, 255, 255)],\n",
    "            'Í∞àÏÉâ': [(10, 50, 20), (20, 200, 150)],\n",
    "            'ÌöåÏÉâ': [(0, 0, 50), (180, 30, 200)],\n",
    "            'Í≤ÄÏ†ï': [(0, 0, 0), (180, 255, 50)],\n",
    "        }\n",
    "\n",
    "        self.class_mapping = {\n",
    "            'Ìù∞ÏÉâ': 'Ìù∞ÏÉâ',\n",
    "            'ÎÖ∏Îûë': 'ÎÖ∏Îûë', 'Ïó∞Îëê': 'ÎÖ∏Îûë',\n",
    "            'ÌïëÌÅ¨': 'ÌïëÌÅ¨', 'Îπ®Í∞ï1': 'ÌïëÌÅ¨', 'Îπ®Í∞ï2': 'ÌïëÌÅ¨',\n",
    "            'Ï£ºÌô©': 'Ïò§Î†åÏßÄ',\n",
    "            'ÌååÎûë': 'Î∏îÎ£®', 'ÎØºÌä∏': 'Î∏îÎ£®', 'Î≥¥Îùº': 'Î∏îÎ£®',\n",
    "            'Í∞àÏÉâ': 'Î∏åÎùºÏö¥', 'ÌöåÏÉâ': 'Î∏åÎùºÏö¥', 'Í≤ÄÏ†ï': 'Î∏åÎùºÏö¥',\n",
    "            'Ï¥àÎ°ù': 'Í∑∏Î¶∞',\n",
    "        }\n",
    "\n",
    "    def analyze_color_hsv(self, image_bgr):\n",
    "        image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "        hsv = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        color_scores = {}\n",
    "        total_pixels = hsv.shape[0] * hsv.shape[1]\n",
    "\n",
    "        for color_name, (lower, upper) in self.color_ranges.items():\n",
    "            mask = cv2.inRange(hsv, np.array(lower), np.array(upper))\n",
    "            ratio = cv2.countNonZero(mask) / total_pixels\n",
    "            color_scores[color_name] = ratio\n",
    "\n",
    "        sorted_colors = sorted(color_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        detected_colors = []\n",
    "        for color_name, score in sorted_colors[:3]:\n",
    "            if score > 0.05:\n",
    "                mapped_color = self.class_mapping.get(color_name, color_name)\n",
    "                if mapped_color not in detected_colors:\n",
    "                    detected_colors.append(mapped_color)\n",
    "\n",
    "        return detected_colors[:2] if detected_colors else ['Ìù∞ÏÉâ']\n",
    "\n",
    "    def detect_division_line(self, image_bgr):\n",
    "        gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)\n",
    "        edges = cv2.Canny(gray, 50, 150)\n",
    "\n",
    "        kernel_h = np.ones((1, 15), np.uint8)\n",
    "        h_lines = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel_h)\n",
    "\n",
    "        kernel_v = np.ones((15, 1), np.uint8)\n",
    "        v_lines = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel_v)\n",
    "\n",
    "        h_count = cv2.countNonZero(h_lines)\n",
    "        v_count = cv2.countNonZero(v_lines)\n",
    "\n",
    "        threshold = image_bgr.shape[0] * 0.3\n",
    "\n",
    "        if h_count > threshold and v_count > threshold:\n",
    "            return True, 'cross'\n",
    "        elif h_count > threshold:\n",
    "            return True, 'horizontal'\n",
    "        elif v_count > threshold:\n",
    "            return True, 'vertical'\n",
    "        else:\n",
    "            return False, None\n",
    "\n",
    "\n",
    "class IntegratedPillDetector:\n",
    "    def __init__(self,\n",
    "             yolo_weights,\n",
    "             shape_color_model_path,\n",
    "             confidence_threshold=0.25,\n",
    "             iou_threshold=0.7,\n",
    "             ocr_languages=['en', 'ko'],\n",
    "             use_gpu=True,\n",
    "             use_hsv_color=True,\n",
    "             vision_api_key: Optional[str] = None,\n",
    "             vision_fallback_threshold: float = 0.99\n",
    "             ):\n",
    "\n",
    "\n",
    "        print(\"ÌÜµÌï© ÌååÏù¥ÌîÑÎùºÏù∏ Ï¥àÍ∏∞Ìôî Ï§ë (ÏÉâÏÉÅ Í∞úÏÑ† Î≤ÑÏ†Ñ)...\")\n",
    "        print(f\"YOLO Î™®Îç∏ Î°úÎî©: {yolo_weights}\")\n",
    "        self.yolo_model = YOLO(yolo_weights)\n",
    "        self.conf_threshold = confidence_threshold\n",
    "        self.iou_threshold = iou_threshold\n",
    "        self.use_hsv_color = use_hsv_color\n",
    "        self.score_line_detector = PillScoreLineDetector()\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if use_gpu and torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        print(f\"Shape+Color Î™®Îç∏ Î°úÎî©: {shape_color_model_path}\")\n",
    "\n",
    "        self.shape_classes = [\n",
    "            'Circular (ÏõêÌòï)',\n",
    "            'Oblong (Ïû•Î∞©Ìòï)',\n",
    "            'Elliptical (ÌÉÄÏõêÌòï)',\n",
    "            'Other (Í∏∞ÌÉÄ)'\n",
    "        ]\n",
    "\n",
    "        self.color_classes = [\n",
    "            'Ìù∞ÏÉâ',\n",
    "            'ÎÖ∏Îûë',\n",
    "            'ÌïëÌÅ¨',\n",
    "            'Ïò§Î†åÏßÄ',\n",
    "            'Î∏îÎ£®',\n",
    "            'Î∏åÎùºÏö¥',\n",
    "            'Í∑∏Î¶∞'\n",
    "        ]\n",
    "\n",
    "        self.shape_transform = transforms.Compose([\n",
    "            PadToSquare(),\n",
    "            transforms.Resize((128, 128)),\n",
    "            transforms.ToTensor(),\n",
    "            ColorNormalizer()\n",
    "        ])\n",
    "\n",
    "        self.shape_color_model, self.model_version = self._load_shape_color_model(shape_color_model_path)\n",
    "\n",
    "        # Google Vision OCR ÏòµÏÖò\n",
    "        self.vision_ocr = None\n",
    "        self.vision_fallback_threshold = vision_fallback_threshold\n",
    "        if vision_api_key:\n",
    "            self.vision_ocr = GoogleVisionOCRWithApiKey(vision_api_key)\n",
    "            print(\"üß† Google Vision OCR ÌôúÏÑ±Ìôî (API key ÏÇ¨Ïö©)\")\n",
    "        else:\n",
    "            print(\"üß† Google Vision OCR ÎπÑÌôúÏÑ±Ìôî (API key ÎØ∏ÏßÄÏ†ï)\")\n",
    "\n",
    "        print(f\"üìù EasyOCR Ï¥àÍ∏∞Ìôî: {ocr_languages} (ÌïúÍµ≠Ïñ¥ ÏßÄÏõê ÌôúÏÑ±Ìôî)\")\n",
    "        self.ocr_reader = easyocr.Reader(ocr_languages, gpu=use_gpu)\n",
    "        self.hsv_analyzer = ImprovedColorAnalyzer()\n",
    "\n",
    "        print(f\"HSV ÏÉâÏÉÅ Î∂ÑÏÑù: {'ÌôúÏÑ±Ìôî' if use_hsv_color else 'ÎπÑÌôúÏÑ±Ìôî'}\")\n",
    "        print(\"Ï¥àÍ∏∞Ìôî ÏôÑÎ£å!\")\n",
    "\n",
    "    def _load_shape_color_model(self, path):\n",
    "        print(f\"Î™®Îç∏ Î°úÎî© ÏãúÎèÑ: {path}\")\n",
    "\n",
    "        try:\n",
    "            checkpoint = torch.load(path, map_location=self.device)\n",
    "\n",
    "            is_dict_checkpoint = 'model_state_dict' in checkpoint\n",
    "            state_dict = checkpoint['model_state_dict'] if is_dict_checkpoint else checkpoint\n",
    "\n",
    "            num_shapes = 4\n",
    "            num_colors = 7\n",
    "\n",
    "            if 'fc_shape.weight' in state_dict:\n",
    "                num_shapes = state_dict['fc_shape.weight'].shape[0]\n",
    "                num_colors = state_dict['fc_color.weight'].shape[0]\n",
    "                model_version = 'v1'\n",
    "                print(f\"Î™®Îç∏ Î≤ÑÏ†Ñ: v1\")\n",
    "                model = ShapeColorResNet_v1(num_shapes, num_colors)\n",
    "\n",
    "            elif 'fc_shape.1.weight' in state_dict:\n",
    "                num_shapes = state_dict['fc_shape.4.weight'].shape[0]\n",
    "                num_colors = state_dict['fc_color.4.weight'].shape[0]\n",
    "                model_version = 'v2'\n",
    "                print(f\"Î™®Îç∏ Î≤ÑÏ†Ñ: v2\")\n",
    "                model = ShapeColorResNet_v2(num_shapes, num_colors)\n",
    "            else:\n",
    "                raise ValueError(\"Ïïå Ïàò ÏóÜÎäî Î™®Îç∏ Íµ¨Ï°∞\")\n",
    "\n",
    "            print(f\"Shape ÌÅ¥ÎûòÏä§: {num_shapes}Í∞ú\")\n",
    "            print(f\"Color ÌÅ¥ÎûòÏä§: {num_colors}Í∞ú\")\n",
    "\n",
    "            model.load_state_dict(state_dict)\n",
    "            model.to(self.device).eval()\n",
    "\n",
    "            if is_dict_checkpoint and 'shape_acc' in checkpoint:\n",
    "                print(f\"Shape Ï†ïÌôïÎèÑ: {checkpoint['shape_acc']:.2f}%\")\n",
    "                print(f\"Color Ï†ïÌôïÎèÑ: {checkpoint['color_acc']:.2f}%\")\n",
    "\n",
    "            print(\"Î™®Îç∏ Î°úÎìú ÏÑ±Í≥µ!\")\n",
    "            return model, model_version\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Î™®Îç∏ Î°úÎìú Ïò§Î•ò: {e}\")\n",
    "            print(\"Í∏∞Î≥∏ Î™®Îç∏Î°ú ÏßÑÌñâ\")\n",
    "            model = ShapeColorResNet_v1(4, 7)\n",
    "            model.to(self.device).eval()\n",
    "            return model, 'v1'\n",
    "\n",
    "    # YOLO\n",
    "    def detect_pills(self, image: np.ndarray) -> List[PillDetection]:\n",
    "        results = self.yolo_model.predict(\n",
    "            image,\n",
    "            conf=self.conf_threshold,\n",
    "            iou=self.iou_threshold,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        detections = []\n",
    "        if len(results) > 0 and results[0].boxes is not None:\n",
    "            boxes = results[0].boxes\n",
    "            for i in range(len(boxes)):\n",
    "                x1, y1, x2, y2 = boxes.xyxy[i].cpu().numpy().astype(int)\n",
    "                confidence = float(boxes.conf[i].cpu().numpy())\n",
    "                crop = image[y1:y2, x1:x2].copy()\n",
    "                detections.append(PillDetection(\n",
    "                    bbox=(x1, y1, x2, y2),\n",
    "                    confidence=confidence,\n",
    "                    crop_image=crop\n",
    "                ))\n",
    "        return detections\n",
    "\n",
    "    def analyze_single_pill(self, crop_image: np.ndarray) -> Dict:\n",
    "        result = {\n",
    "            'colors': [],\n",
    "            'colors_cnn': [],\n",
    "            'colors_hsv': [],\n",
    "            'shape': None,\n",
    "            'shape_confidence': 0.0,\n",
    "            'color_confidence': 0.0,\n",
    "            'has_division_line': False,\n",
    "            'division_line_shape': None,\n",
    "            'engraving_text': None,\n",
    "            'ocr_confidence': 0.0\n",
    "        }\n",
    "\n",
    "        # Shape + Color CNN ÏòàÏ∏°\n",
    "        try:\n",
    "            shape, shape_conf, colors_cnn, color_conf = self.predict_shape_and_color(crop_image)\n",
    "            result['shape'] = shape\n",
    "            result['shape_confidence'] = shape_conf\n",
    "            result['colors_cnn'] = colors_cnn\n",
    "            result['color_confidence'] = color_conf\n",
    "        except Exception as e:\n",
    "            print(f\"CNN Î∂ÑÏÑù Ïò§Î•ò: {e}\")\n",
    "\n",
    "        # HSV ÏÉâÏÉÅ Î∂ÑÏÑù\n",
    "        if self.use_hsv_color:\n",
    "            try:\n",
    "                colors_hsv = self.hsv_analyzer.analyze_color_hsv(crop_image)\n",
    "                result['colors_hsv'] = colors_hsv\n",
    "            except Exception as e:\n",
    "                print(f\"HSV Î∂ÑÏÑù Ïò§Î•ò: {e}\")\n",
    "\n",
    "        # ÏµúÏ¢Ö ÏÉâÏÉÅ Í≤∞Ï†ï (HSV Ïö∞ÏÑ†)\n",
    "        if self.use_hsv_color and result['colors_hsv']:\n",
    "            result['colors'] = result['colors_hsv']\n",
    "        else:\n",
    "            result['colors'] = result['colors_cnn']\n",
    "\n",
    "        # Î∂ÑÌï†ÏÑ† Í≤ÄÏ∂ú\n",
    "        try:\n",
    "            line_count, line_type = self.score_line_detector.extract_score_lines(crop_image)\n",
    "            result['has_division_line'] = line_count > 0\n",
    "            result['division_line_shape'] = line_type\n",
    "        except Exception as e:\n",
    "            print(f\"Î∂ÑÌï†ÏÑ† Í≤ÄÏ∂ú Ïò§Î•ò: {e}\")\n",
    "\n",
    "        # OCR\n",
    "        try:\n",
    "            text, confidence = self.extract_text_from_pill(crop_image)\n",
    "            result['engraving_text'] = text\n",
    "            result['ocr_confidence'] = confidence\n",
    "        except Exception as e:\n",
    "            print(f\"OCR Ïò§Î•ò: {e}\")\n",
    "\n",
    "        return result\n",
    "\n",
    "    # CNN Í∏∞Î∞ò ShapeÏôÄ Color ÏòàÏ∏°\n",
    "    def predict_shape_and_color(self, image_np):\n",
    "        if self.shape_color_model is None:\n",
    "            return None, 0.0, [], 0.0\n",
    "\n",
    "        img_rgb = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB)\n",
    "        pil_img = Image.fromarray(img_rgb)\n",
    "\n",
    "        tensor = self.shape_transform(pil_img).unsqueeze(0).to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            shape_out, color_out = self.shape_color_model(tensor)\n",
    "\n",
    "            # Shape ÏòàÏ∏°\n",
    "            shape_probs = torch.nn.functional.softmax(shape_out, dim=1)\n",
    "            shape_conf, shape_idx = torch.max(shape_probs, 1)\n",
    "            shape_name = self.shape_classes[shape_idx.item()]\n",
    "\n",
    "            # Color ÏòàÏ∏°\n",
    "            color_probs = torch.nn.functional.softmax(color_out, dim=1)\n",
    "            top2_probs, top2_indices = torch.topk(color_probs, k=2, dim=1)\n",
    "\n",
    "            colors = []\n",
    "            colors.append(self.color_classes[top2_indices[0][0].item()])\n",
    "\n",
    "            if top2_probs[0][1].item() > 0.3:\n",
    "                second_color = self.color_classes[top2_indices[0][1].item()]\n",
    "                if second_color != colors[0]:\n",
    "                    colors.append(second_color)\n",
    "\n",
    "            avg_color_conf = top2_probs[0][0].item()\n",
    "\n",
    "        return shape_name, shape_conf.item(), colors, avg_color_conf\n",
    "\n",
    "    # OCR\n",
    "    def extract_text_from_pill(self, image: np.ndarray) -> Tuple[Optional[str], float]:\n",
    "        preprocessed = self.preprocess_for_ocr(image)\n",
    "\n",
    "        # EasyOCR\n",
    "        best_text, best_confidence = None, 0.0\n",
    "\n",
    "        for angle in [0, 45, 90, 135, 180, 225, 270, 315]:\n",
    "            rotated = self.rotate_image(preprocessed, angle) if angle != 0 else preprocessed\n",
    "            try:\n",
    "                results = self.ocr_reader.readtext(\n",
    "                    rotated,\n",
    "                    detail=1,\n",
    "                    paragraph=False\n",
    "                )\n",
    "                if results:\n",
    "                    texts = [r[1] for r in results]\n",
    "                    confidences = [r[2] for r in results]\n",
    "                    combined_text = ' '.join(texts)\n",
    "                    avg_confidence = float(np.mean(confidences))\n",
    "\n",
    "                    if avg_confidence > best_confidence:\n",
    "                        best_text = combined_text\n",
    "                        best_confidence = avg_confidence\n",
    "            except Exception as e:\n",
    "                continue\n",
    "\n",
    "        # Í≥µÎ∞± Ï†ïÎ¶¨\n",
    "        if best_text:\n",
    "            best_text = ' '.join(best_text.split())\n",
    "\n",
    "        # Vision Falback\n",
    "        if self.vision_ocr is not None and (best_text is None or best_confidence < self.vision_fallback_threshold):\n",
    "            bgr_for_vision = cv2.cvtColor(preprocessed, cv2.COLOR_GRAY2BGR)\n",
    "            try:\n",
    "                vision_text, vision_conf = self.vision_ocr.read_single_image(bgr_for_vision)\n",
    "                if vision_text and vision_conf >= best_confidence:\n",
    "                    best_text = vision_text\n",
    "                    best_confidence = vision_conf\n",
    "            except Exception as e:\n",
    "                print(f\"Vision OCR Ïò§Î•ò: {e}\")\n",
    "\n",
    "        if best_text:\n",
    "            return best_text, best_confidence\n",
    "        return None, 0.0\n",
    "\n",
    "\n",
    "    def preprocess_for_ocr(self, image: np.ndarray) -> np.ndarray:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "        return clahe.apply(gray)\n",
    "\n",
    "    def rotate_image(self, image: np.ndarray, angle: float) -> np.ndarray:\n",
    "        (h, w) = image.shape[:2]\n",
    "        center = (w // 2, h // 2)\n",
    "        M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "        return cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC,\n",
    "                             borderMode=cv2.BORDER_REPLICATE)\n",
    "\n",
    "    def process_image(self, image_path: str, visualize: bool = False) -> PillAnalysisResult:\n",
    "        image = cv2.imread(str(image_path))\n",
    "        if image is None:\n",
    "            raise ValueError(f\"Ïù¥ÎØ∏ÏßÄ Î°úÎìú Ïã§Ìå®: {image_path}\")\n",
    "\n",
    "        detections = self.detect_pills(image)\n",
    "        pills_info = []\n",
    "\n",
    "        for idx, detection in enumerate(detections, 1):\n",
    "            analysis = self.analyze_single_pill(detection.crop_image)\n",
    "            pill_info = {\n",
    "                'pill_id': idx,\n",
    "                'bbox': detection.bbox,\n",
    "                'detection_confidence': detection.confidence,\n",
    "                **analysis\n",
    "            }\n",
    "            pills_info.append(pill_info)\n",
    "\n",
    "        result = PillAnalysisResult(detection_count=len(detections), pills=pills_info)\n",
    "\n",
    "        if visualize:\n",
    "            self.visualize_results(image, detections, pills_info, image_path)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def visualize_results(self, image, detections, pills_info, image_path):\n",
    "        vis_image = image.copy()\n",
    "        for detection, info in zip(detections, pills_info):\n",
    "            x1, y1, x2, y2 = detection.bbox\n",
    "            cv2.rectangle(vis_image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            label = f\"#{info['pill_id']}\"\n",
    "            cv2.putText(vis_image, label, (x1, y1-10),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.imshow(cv2.cvtColor(vis_image, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Í≤ÄÏ∂ú Í≤∞Í≥º: {len(detections)}Í∞ú ÏïΩ Î∞úÍ≤¨')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Î™®Îç∏ Î≤ÑÏ†Ñ: {self.model_version}\")\n",
    "        print(f\"ÏÉâÏÉÅ Î∂ÑÏÑù: HSV {'ÌôúÏÑ±Ìôî' if self.use_hsv_color else 'CNNÎßå'}\")\n",
    "        print(f\"Í≤ÄÏ∂úÎêú ÏïΩ: {len(detections)}Í∞ú\")\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "        for info in pills_info:\n",
    "            print(f\"\\nÏïΩ #{info['pill_id']}\")\n",
    "            print(f\"  Í≤ÄÏ∂ú Ïã†Î¢∞ÎèÑ: {info['detection_confidence']:.2%}\")\n",
    "            print(f\"  Î™®Ïñë: {info['shape']} (Ïã†Î¢∞ÎèÑ: {info['shape_confidence']:.2%})\")\n",
    "\n",
    "            # ÏÉâÏÉÅ ÎπÑÍµê Ï∂úÎ†•\n",
    "            if self.use_hsv_color:\n",
    "                print(f\"   ÏÉâÏÉÅ (HSV): {', '.join(info['colors_hsv'])}\")\n",
    "                print(f\"   ÏÉâÏÉÅ (CNN): {', '.join(info['colors_cnn'])} (Ïã†Î¢∞ÎèÑ: {info['color_confidence']:.2%})\")\n",
    "                print(f\"   ÏµúÏ¢Ö ÏÉâÏÉÅ: {', '.join(info['colors'])}\")\n",
    "            else:\n",
    "                print(f\"   ÏÉâÏÉÅ: {', '.join(info['colors'])} (Ïã†Î¢∞ÎèÑ: {info['color_confidence']:.2%})\")\n",
    "\n",
    "            print(f\"   Î∂ÑÌï†ÏÑ†: {info['division_line_shape'] if info['has_division_line'] else 'ÏóÜÏùå'}\")\n",
    "\n",
    "            if info['engraving_text']:\n",
    "                print(f\"   Í∞ÅÏù∏: {info['engraving_text']} (Ïã†Î¢∞ÎèÑ: {info['ocr_confidence']:.2%})\")\n",
    "            else:\n",
    "                print(f\"   Í∞ÅÏù∏: ÏóÜÏùå\")"
   ],
   "outputs": [],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T01:45:53.809211Z",
     "start_time": "2025-12-12T01:45:53.802761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import base64\n",
    "import requests\n",
    "import cv2\n",
    "\n",
    "class GoogleVisionOCRWithApiKey:\n",
    "    def __init__(self, api_key: str):\n",
    "        self.api_key = api_key\n",
    "        self.endpoint = f\"https://vision.googleapis.com/v1/images:annotate?key={self.api_key}\"\n",
    "\n",
    "    def read_single_image(self, image_bgr):\n",
    "        \"\"\"\n",
    "        image_bgr: BGR numpy\n",
    "        return: (cleaned_text, None ÎòêÎäî ÎåÄÏ∂© conf)\n",
    "        \"\"\"\n",
    "        # 1) BGR -> RGB -> JPEG Ïù∏ÏΩîÎî©\n",
    "        img_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "        ok, buf = cv2.imencode(\".jpg\", img_rgb)\n",
    "        if not ok:\n",
    "            return None, 0.0\n",
    "\n",
    "        # 2) base64 Ïù∏ÏΩîÎî©\n",
    "        img_base64 = base64.b64encode(buf.tobytes()).decode(\"utf-8\")\n",
    "\n",
    "        payload = {\n",
    "            \"requests\": [\n",
    "                {\n",
    "                    \"image\": {\n",
    "                        \"content\": img_base64\n",
    "                    },\n",
    "                    \"features\": [\n",
    "                        {\"type\": \"TEXT_DETECTION\"}  # Í∞ÅÏù∏Ïù¥ÎùºÎ©¥ TEXT_DETECTIONÏù¥Î©¥ Ï∂©Î∂Ñ\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        resp = requests.post(self.endpoint, json=payload)\n",
    "        if resp.status_code != 200:\n",
    "            print(\"Vision API Ïò§Î•ò:\", resp.status_code, resp.text[:200])\n",
    "            return None, 0.0\n",
    "\n",
    "        data = resp.json()\n",
    "        try:\n",
    "            annotations = data[\"responses\"][0].get(\"textAnnotations\", [])\n",
    "        except (KeyError, IndexError):\n",
    "            return None, 0.0\n",
    "\n",
    "        if not annotations:\n",
    "            return None, 0.0\n",
    "\n",
    "        full_text = annotations[0][\"description\"]\n",
    "\n",
    "        # ÏïΩ Í∞ÅÏù∏Ïö©: ÏòÅÎ¨∏+Ïà´ÏûêÎßå ÎÇ®Í∏∞Í≥† Í≥µÎ∞± Ï†ïÎ¶¨\n",
    "        filtered = []\n",
    "        for ch in full_text:\n",
    "            if ch.isalnum():\n",
    "                filtered.append(ch.upper())\n",
    "            elif ch.isspace():\n",
    "                filtered.append(\" \")\n",
    "        cleaned = \" \".join(\"\".join(filtered).split())\n",
    "\n",
    "        if not cleaned:\n",
    "            return None, 0.0\n",
    "\n",
    "        # Vision RESTÏóêÏÑúÎäî Ïã¨ÌîåÌïòÍ≤å confidenceÎ•º Ïïà Ï£ºÎãàÍπå ÏùºÎã® 1.0ÏúºÎ°ú\n",
    "        return cleaned, 1.0\n"
   ],
   "outputs": [],
   "execution_count": 99
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6Ô∏è‚É£ ÌååÏù¥ÌîÑÎùºÏù∏ Ï¥àÍ∏∞Ìôî"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T01:45:55.995290Z",
     "start_time": "2025-12-12T01:45:53.816125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "detector = IntegratedPillDetector(\n",
    "    yolo_weights=YOLO_WEIGHTS,\n",
    "    shape_color_model_path=SHAPE_COLOR_MODEL,\n",
    "    vision_api_key=\"AIzaSyCuYxmCDJbqzYUb3oDSmVjEvdjEfynwnhM\",\n",
    "    confidence_threshold=0.25,\n",
    "    iou_threshold=0.7,\n",
    "    ocr_languages=['en', 'ko'],\n",
    "    use_gpu=True,\n",
    "    use_hsv_color=True\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÌÜµÌï© ÌååÏù¥ÌîÑÎùºÏù∏ Ï¥àÍ∏∞Ìôî Ï§ë (ÏÉâÏÉÅ Í∞úÏÑ† Î≤ÑÏ†Ñ)...\n",
      "YOLO Î™®Îç∏ Î°úÎî©: C:\\Users\\yooni\\PycharmProjects\\pillDetection\\weights\\best.pt\n",
      "Shape+Color Î™®Îç∏ Î°úÎî©: C:\\Users\\yooni\\PycharmProjects\\pillDetection\\weights\\pill_shape_color_resnet50_improved_best_shape.pth\n",
      "Î™®Îç∏ Î°úÎî© ÏãúÎèÑ: C:\\Users\\yooni\\PycharmProjects\\pillDetection\\weights\\pill_shape_color_resnet50_improved_best_shape.pth\n",
      "Î™®Îç∏ Î≤ÑÏ†Ñ: v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape ÌÅ¥ÎûòÏä§: 4Í∞ú\n",
      "Color ÌÅ¥ÎûòÏä§: 7Í∞ú\n",
      "Shape Ï†ïÌôïÎèÑ: 97.76%\n",
      "Color Ï†ïÌôïÎèÑ: 94.49%\n",
      "Î™®Îç∏ Î°úÎìú ÏÑ±Í≥µ!\n",
      "üß† Google Vision OCR ÌôúÏÑ±Ìôî (API key ÏÇ¨Ïö©)\n",
      "üìù EasyOCR Ï¥àÍ∏∞Ìôî: ['en', 'ko'] (ÌïúÍµ≠Ïñ¥ ÏßÄÏõê ÌôúÏÑ±Ìôî)\n",
      "HSV ÏÉâÏÉÅ Î∂ÑÏÑù: ÌôúÏÑ±Ìôî\n",
      "Ï¥àÍ∏∞Ìôî ÏôÑÎ£å!\n"
     ]
    }
   ],
   "execution_count": 100
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 7Ô∏è‚É£ Îã®Ïùº Ïù¥ÎØ∏ÏßÄ Ï≤òÎ¶¨"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T01:45:56.158576Z",
     "start_time": "2025-12-12T01:45:56.086598Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "ROOT = Path().resolve()\n",
    "CSV_PATH =  ROOT / \"drug_info_unique_drug_id_final.csv\"\n",
    "\n",
    "drug_db = pd.read_csv(CSV_PATH)\n",
    "\n",
    "print(\"shape:\", drug_db.shape)\n",
    "print(\"columns:\", list(drug_db.columns))\n",
    "print(\"first column name repr:\", repr(drug_db.columns[0]))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4023, 52)\n",
      "columns: ['drug_id', 'drug_N', 'file_name', 'imgfile', 'item_seq', 'json_file', 'back_color', 'camera_la', 'camera_lo', 'change_date', 'chart', 'color_class1', 'color_class2', 'di_class_no', 'di_company_mf', 'di_company_mf_en', 'di_edi_code', 'di_etc_otc_code', 'di_item_permit_date', 'dl_company', 'dl_company_en', 'dl_custom_shape', 'dl_idx', 'dl_mapping_code', 'dl_material', 'dl_material_en', 'dl_name', 'dl_name_en', 'drug_S', 'drug_dir', 'drug_shape', 'form_code_name', 'height', 'id', 'img_key', 'img_regist_ts', 'leng_long', 'leng_short', 'light_color', 'line_back', 'line_front', 'mark_code_back', 'mark_code_back_anal', 'mark_code_back_img', 'mark_code_front', 'mark_code_front_anal', 'mark_code_front_img', 'print_back', 'print_front', 'size', 'thick', 'width']\n",
      "first column name repr: 'drug_id'\n"
     ]
    }
   ],
   "execution_count": 101
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T01:45:56.188173Z",
     "start_time": "2025-12-12T01:45:56.177936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def search_similar_pills(pill_info, db: pd.DataFrame, top_k: int = 5):\n",
    "    pill_colors = pill_info.get(\"colors\", [])\n",
    "    pill_shape = pill_info.get(\"shape\")\n",
    "    pill_line_info = pill_info.get(\"engraving_text\")\n",
    "    pill_line_shape = pill_info.get(\"division_line_shape\")\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    for i in range(len(db)):\n",
    "        row = db.iloc[i]\n",
    "\n",
    "        color_s = _color_family_match_score(pill_colors, row)\n",
    "        shape_s = _shape_match_score(pill_shape, row)\n",
    "        line_s = _line_match_score(pill_info, row)\n",
    "        engr_s = _engraving_similarity(pill_line_info, row)\n",
    "\n",
    "        total = (\n",
    "            engr_s * 3.0 +\n",
    "            color_s * 2.0 +\n",
    "            shape_s * 1.5 +\n",
    "            line_s * 1.0\n",
    "        )\n",
    "\n",
    "        scores.append(\n",
    "            (float(total), float(engr_s), float(color_s),\n",
    "             float(shape_s), float(line_s), i)\n",
    "        )\n",
    "\n",
    "    if not scores:\n",
    "        return []\n",
    "\n",
    "    scores.sort(key=lambda x: x[0], reverse=True)\n",
    "    top = scores[:top_k]\n",
    "\n",
    "    candidates = []\n",
    "    for total, engr_s, color_s, shape_s, line_s, idx in top:\n",
    "        row = db.iloc[idx]\n",
    "\n",
    "        candidates.append({\n",
    "            \"drug_id\": safe_str(row[\"drug_id\"]),\n",
    "            \"drug_N\": safe_str(row[\"drug_N\"]),\n",
    "            \"dl_name\": safe_str(row[\"dl_name\"]),\n",
    "            \"dl_name_en\": safe_str(row[\"dl_name_en\"]),\n",
    "            \"company\": safe_str(row[\"dl_company\"]),\n",
    "            \"drug_shape\": safe_str(row[\"drug_shape\"]),\n",
    "            \"chart\": safe_str(row[\"chart\"]),\n",
    "            \"color_class1\": safe_str(row[\"color_class1\"]),\n",
    "            \"color_class2\": safe_str(row[\"color_class2\"]),\n",
    "            \"print_front\": safe_str(row[\"print_front\"]),\n",
    "            \"print_back\": safe_str(row[\"print_back\"]),\n",
    "            \"score_total\": total,\n",
    "            \"score_engraving\": engr_s,\n",
    "            \"score_color\": color_s,\n",
    "            \"score_shape\": shape_s,\n",
    "            \"score_line\": line_s,\n",
    "        })\n",
    "\n",
    "    return candidates\n"
   ],
   "outputs": [],
   "execution_count": 102
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T01:45:56.202004Z",
     "start_time": "2025-12-12T01:45:56.194788Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def safe_str(v):\n",
    "    if pd.isna(v):\n",
    "        return \"\"\n",
    "    return str(v)\n",
    "\n",
    "# Í∞ÅÏù∏ Ïú†ÏÇ¨ÎèÑ\n",
    "_SIMILAR_GROUPS = [\n",
    "    \"0ODQ\",\n",
    "    \"1IL\",\n",
    "    \"2Z\",\n",
    "    \"5S\",\n",
    "    \"6G\",\n",
    "    \"8B\",\n",
    "    \"MW\",\n",
    "]\n",
    "\n",
    "_CHAR_MAP = {}\n",
    "for group in _SIMILAR_GROUPS:\n",
    "    rep = group[0]\n",
    "    for ch in group:\n",
    "        _CHAR_MAP[ch] = rep\n",
    "\n",
    "def _normalize_for_engraving(s: str) -> str:\n",
    "    if pd.isna(s) or s is None:\n",
    "        return \"\"\n",
    "    s = str(s).upper()\n",
    "    out = []\n",
    "    for ch in s:\n",
    "        if \"A\" <= ch <= \"Z\" or \"0\" <= ch <= \"9\":\n",
    "            out.append(_CHAR_MAP.get(ch, ch))\n",
    "        elif \"Í∞Ä\" <= ch <= \"Ìû£\":\n",
    "            out.append(ch)\n",
    "        else:\n",
    "            continue\n",
    "    return \"\".join(out)\n",
    "\n",
    "def _engraving_similarity(pill_text, row) -> float:\n",
    "    if not pill_text:\n",
    "        return 0.0\n",
    "\n",
    "    pill_norm = _normalize_for_engraving(pill_text)\n",
    "    if not pill_norm:\n",
    "        return 0.0\n",
    "\n",
    "    candidate_cols = [\n",
    "        \"print_front\", \"print_back\",\n",
    "        \"mark_code_front\", \"mark_code_back\",\n",
    "        \"mark_code_front_anal\", \"mark_code_back_anal\",\n",
    "    ]\n",
    "\n",
    "    best = 0.0\n",
    "    for col in candidate_cols:\n",
    "        if col not in row.index:\n",
    "            continue\n",
    "        ref_norm = _normalize_for_engraving(row[col])\n",
    "        if not ref_norm:\n",
    "            continue\n",
    "\n",
    "        if pill_norm in ref_norm or ref_norm in pill_norm:\n",
    "            short, long_ = sorted([pill_norm, ref_norm], key=len)\n",
    "            sim = len(short) / len(long_)\n",
    "        else:\n",
    "            sim = SequenceMatcher(None, pill_norm, ref_norm).ratio()\n",
    "\n",
    "        if sim > best:\n",
    "            best = sim\n",
    "\n",
    "    return float(best)"
   ],
   "outputs": [],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T01:45:56.215030Z",
     "start_time": "2025-12-12T01:45:56.208917Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ÏÉâÏÉÅ Îß§Ïπ≠\n",
    "COLOR_FAMILIES = {\n",
    "    \"Ìù∞ÏÉâ\": [\"ÌïòÏñë\", \"Ìù∞ÏÉâ\", \"Î∞±ÏÉâ\", \"Ï£ºÎ∞±ÏÉâ\", \"Ïú†Î∞±ÏÉâ\", \"Ï£ºÍ¥ëÏÉâ\"],\n",
    "    \"ÎÖ∏Îûë\": [\"ÎÖ∏Îûë\", \"Ìô©ÏÉâ\", \"ÎØ∏Ìô©ÏÉâ\", \"Ïó∞ÎÖ∏Îûë\", \"Ï†ÑÍµ¨ÏÉâ\"],\n",
    "    \"ÌïëÌÅ¨\": [\"Î∂ÑÌôç\", \"ÌïëÌÅ¨\", \"ÌôçÏÉâ\", \"Ï†ÅÏÉâ\", \"Ïó∞Î∂ÑÌôç\"],\n",
    "    \"Ïò§Î†åÏßÄ\": [\"Ï£ºÌô©\", \"Ïò§Î†åÏßÄ\"],\n",
    "    \"Î∏îÎ£®\": [\"ÌååÎûë\", \"Ï≤≠ÏÉâ\", \"Íµ∞Ï≤≠\", \"ÎÇ®ÏÉâ\", \"Ï≤≠ÎÖπÏÉâ\"],\n",
    "    \"Î∏åÎùºÏö¥\": [\"Í∞àÏÉâ\", \"Í∞à\", \"Í∞àÏÉâÏ°∞\", \"Í∞àÏÉâÎπõ\", \"ÌöåÍ∞àÏÉâ\", \"ÌöåÏÉâ\", \"ÌùëÍ∞àÏÉâ\"],\n",
    "    \"Í∑∏Î¶∞\": [\"Ï¥àÎ°ù\", \"ÎÖπÏÉâ\", \"Ïó∞Îëê\", \"Ìô©Î°ùÏÉâ\"],\n",
    "}\n",
    "\n",
    "def _color_family_match_score(pill_colors, row) -> float:\n",
    "    if not pill_colors:\n",
    "        return 0.0\n",
    "\n",
    "    txt = \" \".join(\n",
    "        [\n",
    "            safe_str(row.get(col, \"\"))\n",
    "            for col in [\"chart\", \"color_class1\", \"color_class2\", \"light_color\"]\n",
    "            if col in row.index\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if not txt:\n",
    "        return 0.0\n",
    "\n",
    "    matches = 0\n",
    "    for c in pill_colors:\n",
    "        family_keywords = COLOR_FAMILIES.get(c, [c])\n",
    "        if any(k and k in txt for k in family_keywords):\n",
    "            matches += 1\n",
    "\n",
    "    if matches == 0:\n",
    "        return 0.0\n",
    "\n",
    "    return float(matches / len(pill_colors))"
   ],
   "outputs": [],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T01:45:56.226203Z",
     "start_time": "2025-12-12T01:45:56.220895Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Î™®Ïñë Îß§Ïπ≠\n",
    "SHAPE_KEYWORDS = {\n",
    "    \"ELLIPTICAL\": [\"ÌÉÄÏõê\", \"ÌÉÄÏõêÌòï\"],\n",
    "    \"OBLONG\": [\"Ïû•Î∞©Ìòï\", \"Ïû•Î∞©\"],\n",
    "    \"ROUND\": [\"ÏõêÌòï\", \"Ïõê\"],\n",
    "    \"TRIANGLE\": [\"ÏÇºÍ∞Å\", \"ÏÇºÍ∞ÅÌòï\"],\n",
    "    \"PENTAGON\": [\"Ïò§Í∞Å\", \"Ïò§Í∞ÅÌòï\"],\n",
    "    \"HEXAGON\": [\"Ïú°Í∞Å\", \"Ïú°Í∞ÅÌòï\"],\n",
    "    \"OCTAGON\": [\"ÌåîÍ∞Å\", \"ÌåîÍ∞ÅÌòï\"],\n",
    "}\n",
    "\n",
    "def _shape_match_score(pill_shape, row) -> float:\n",
    "    \"\"\"Î™®Ïñë Îß§Ïπ≠ Ï†êÏàò (0~1). ÏòÅÏñ¥+ÌïúÍ∏Ä ÏÑûÏù∏ shapeÎèÑ ÌïúÍ∏Ä ÌÇ§ÏõåÎìúÎ°ú ÎäêÏä®ÌïòÍ≤å ÎπÑÍµê.\"\"\"\n",
    "    if not pill_shape:\n",
    "        return 0.0\n",
    "\n",
    "    pill_shape_u = str(pill_shape).upper()\n",
    "    txt = \" \".join(\n",
    "        [\n",
    "            safe_str(row.get(col, \"\"))\n",
    "            for col in [\"drug_shape\", \"chart\", \"dl_custom_shape\"]\n",
    "            if col in row.index\n",
    "        ]\n",
    "    ).upper()\n",
    "\n",
    "    if not txt:\n",
    "        return 0.0\n",
    "\n",
    "    score = 0.0\n",
    "\n",
    "    for key, kws in SHAPE_KEYWORDS.items():\n",
    "        if key in pill_shape_u:\n",
    "            if any(kw in txt for kw in kws):\n",
    "                score = 1.0\n",
    "            break\n",
    "\n",
    "    if score == 0.0:\n",
    "        rough_kws = [\"ÏõêÌòï\", \"Ïû•Î∞©Ìòï\", \"ÌÉÄÏõê\", \"ÏÇºÍ∞Å\", \"ÌåîÍ∞Å\", \"Ï†ïÏ†ú\"]\n",
    "        if any(kw in txt for kw in rough_kws):\n",
    "            score = 0.5\n",
    "\n",
    "    return float(score)"
   ],
   "outputs": [],
   "execution_count": 105
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T01:45:56.237172Z",
     "start_time": "2025-12-12T01:45:56.232539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _line_match_score(pill_info, row) -> float:\n",
    "    has_line_pill = pill_info.get(\"has_division_line\", False)\n",
    "\n",
    "    txt = \" \".join(\n",
    "        [\n",
    "            safe_str(row.get(col, \"\"))\n",
    "            for col in [\"chart\", \"line_front\", \"line_back\"]\n",
    "            if col in row.index\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if not txt:\n",
    "        return 0.0\n",
    "\n",
    "    line_front = safe_str(row.get(\"line_front\", \"\"))\n",
    "    line_back = safe_str(row.get(\"line_back\", \"\"))\n",
    "\n",
    "    has_line_db = (\n",
    "        (\"Î∂ÑÌï†\" in txt)\n",
    "        or (line_front not in [\"\", \"nan\"])  # \"-\" Ï†úÍ±∞!\n",
    "        or (line_back not in [\"\", \"nan\"])   # \"-\" Ï†úÍ±∞!\n",
    "    )\n",
    "\n",
    "    return 1.0 if has_line_pill and has_line_db else 0.0"
   ],
   "outputs": [],
   "execution_count": 106
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T01:45:56.244874Z",
     "start_time": "2025-12-12T01:45:56.243078Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T01:45:56.256747Z",
     "start_time": "2025-12-12T01:45:56.250727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_image = \"/content/drive/MyDrive/Final Output/K-000250-000573-002483-006192_0_2_0_2_70_000_200.png\"\n",
    "\n",
    "if os.path.exists(test_image):\n",
    "    print(f\"Ïù¥ÎØ∏ÏßÄ Ï≤òÎ¶¨ Ï§ë: {test_image}\\n\")\n",
    "\n",
    "    result = detector.process_image(\n",
    "        image_path=test_image,\n",
    "        visualize=True\n",
    "    )\n",
    "\n",
    "    for pill in result.pills:\n",
    "        print(f\"\\n- ÏïΩ #{pill['pill_id']}\")\n",
    "        print(f\"   ÏòàÏ∏° ÏÉâÏÉÅ: {pill.get('colors')}\")\n",
    "        print(f\"   ÏòàÏ∏° Î™®Ïñë: {pill.get('shape')}\")\n",
    "        print(f\"   Í∞ÅÏù∏: {pill.get('engraving_text')} (conf={pill.get('ocr_confidence', 0):.2f})\")\n",
    "\n",
    "        candidates = search_similar_pills(pill, drug_db, top_k=5)\n",
    "        pill[\"candidates\"] = candidates\n",
    "\n",
    "        print(\"   - Top 5 ÌõÑÎ≥¥:\")\n",
    "        for i, c in enumerate(candidates, 1):\n",
    "            print(\n",
    "                f\"    {i}. {c['drug_id']} | {c['dl_name']} ({c['company']})  \"\n",
    "                f\"total={c['score_total']:.3f}  \"\n",
    "                f\"[engr={c['score_engraving']:.2f}, color={c['score_color']:.2f}, \"\n",
    "                f\"shape={c['score_shape']:.2f}, line={c['score_line']:.2f}]\"\n",
    "            )\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Í≤ÄÏ∂úÎêú ÏïΩ Í∞úÏàò: {result.detection_count}Í∞ú\\n\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "else:\n",
    "    print(f\"Ïù¥ÎØ∏ÏßÄÎ•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§: {test_image}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ïù¥ÎØ∏ÏßÄÎ•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§: /content/drive/MyDrive/Final Output/K-000250-000573-002483-006192_0_2_0_2_70_000_200.png\n"
     ]
    }
   ],
   "execution_count": 107
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 8Ô∏è‚É£ Î∞∞Ïπò Ï≤òÎ¶¨ (1000Í∞ú)"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T01:45:56.276026Z",
     "start_time": "2025-12-12T01:45:56.265088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ÌÉÄÍ≤ü ÏïΩÎ¨º ID Ï∂îÏ∂ú\n",
    "def extract_target_ids(filename):\n",
    "    basename = os.path.basename(filename)\n",
    "    prefix = basename.split('_')[0]\n",
    "    ids = prefix.split('-')[1:]\n",
    "    target_ids = [f\"K-{id}\" for id in ids if id]\n",
    "    return target_ids[:4]\n",
    "\n",
    "def evaluate_all_images(max_samples=10):\n",
    "    image_files = [\n",
    "        os.path.join(IMAGE_DIR, f)\n",
    "        for f in os.listdir(IMAGE_DIR)\n",
    "        if f.endswith(('.png', '.jpg', '.jpeg'))\n",
    "    ]\n",
    "\n",
    "    print(f\"Ï¥ù {len(image_files)}Í∞ú Ïù¥ÎØ∏ÏßÄ Î∞úÍ≤¨\")\n",
    "\n",
    "    if len(image_files) > max_samples:\n",
    "        image_files = random.sample(image_files, max_samples)\n",
    "        print(f\"Ïù¥ Ï§ë ÎûúÎç§ {max_samples}Í∞úÎßå ÏÑ†ÌÉùÌï¥ÏÑú ÌèâÍ∞ÄÌï©ÎãàÎã§.\")\n",
    "    else:\n",
    "        print(f\"Ï†ÑÏ≤¥ {len(image_files)}Í∞úÍ∞Ä 1000Í∞ú Ïù¥ÌïòÎùºÏÑú Ï†ÑÎ∂Ä ÌèâÍ∞ÄÌï©ÎãàÎã§.\")\n",
    "\n",
    "    results_list = []\n",
    "\n",
    "    for img_path in tqdm(image_files, desc=\"Ïù¥ÎØ∏ÏßÄ Ï≤òÎ¶¨ Ï§ë\"):\n",
    "        try:\n",
    "            target_ids = extract_target_ids(img_path)\n",
    "            result = detector.process_image(\n",
    "                image_path=img_path,\n",
    "                visualize=False\n",
    "            )\n",
    "\n",
    "            for pill in result.pills:\n",
    "                # Top 9 ÌõÑÎ≥¥ Í≤ÄÏÉâ\n",
    "                candidates = search_similar_pills(pill, drug_db, top_k=9)\n",
    "\n",
    "                # ÏòàÏ∏°Îêú ID Î¶¨Ïä§Ìä∏ (Top 9)\n",
    "                predicted_ids = [c['drug_id'] for c in candidates]\n",
    "\n",
    "                hit_top1 = predicted_ids[0] in target_ids if len(predicted_ids) > 0 else False\n",
    "                hit_top3 = any(pid in target_ids for pid in predicted_ids[:3])\n",
    "                hit_top5 = any(pid in target_ids for pid in predicted_ids[:5])\n",
    "                hit_top9 = any(pid in target_ids for pid in predicted_ids[:9])\n",
    "\n",
    "                record = {\n",
    "                    'image_path': img_path,\n",
    "                    'filename': os.path.basename(img_path),\n",
    "                    'pill_id': pill['pill_id'],\n",
    "                    'target_ids': ','.join(target_ids),\n",
    "                    'predicted_ids': ','.join(predicted_ids),\n",
    "\n",
    "                    'pred_colors': ','.join(pill.get('colors', [])),\n",
    "                    'pred_shape': pill.get('shape', ''),\n",
    "                    'pred_engraving': pill.get('engraving_text', ''),\n",
    "                    'ocr_confidence': pill.get('ocr_confidence', 0.0),\n",
    "\n",
    "                    # Top 1 ÌõÑÎ≥¥ ÏÉÅÏÑ∏ Ï†ïÎ≥¥\n",
    "                    'top1_drug_id': candidates[0]['drug_id'] if len(candidates) > 0 else '',\n",
    "                    'top1_drug_name': candidates[0]['dl_name'] if len(candidates) > 0 else '',\n",
    "                    'top1_company': candidates[0]['company'] if len(candidates) > 0 else '',\n",
    "                    'top1_score_total': candidates[0]['score_total'] if len(candidates) > 0 else 0.0,\n",
    "                    'top1_score_engraving': candidates[0]['score_engraving'] if len(candidates) > 0 else 0.0,\n",
    "                    'top1_score_color': candidates[0]['score_color'] if len(candidates) > 0 else 0.0,\n",
    "                    'top1_score_shape': candidates[0]['score_shape'] if len(candidates) > 0 else 0.0,\n",
    "                    'top1_score_line': candidates[0]['score_line'] if len(candidates) > 0 else 0.0,\n",
    "\n",
    "                    # Top 2 ÌõÑÎ≥¥\n",
    "                    'top2_drug_id': candidates[1]['drug_id'] if len(candidates) > 1 else '',\n",
    "                    'top2_drug_name': candidates[1]['dl_name'] if len(candidates) > 1 else '',\n",
    "                    'top2_score_total': candidates[1]['score_total'] if len(candidates) > 1 else 0.0,\n",
    "\n",
    "                    # Top 3 ÌõÑÎ≥¥\n",
    "                    'top3_drug_id': candidates[2]['drug_id'] if len(candidates) > 2 else '',\n",
    "                    'top3_drug_name': candidates[2]['dl_name'] if len(candidates) > 2 else '',\n",
    "                    'top3_score_total': candidates[2]['score_total'] if len(candidates) > 2 else 0.0,\n",
    "\n",
    "                    # Top 4 ÌõÑÎ≥¥\n",
    "                    'top4_drug_id': candidates[3]['drug_id'] if len(candidates) > 3 else '',\n",
    "                    'top4_drug_name': candidates[3]['dl_name'] if len(candidates) > 3 else '',\n",
    "                    'top4_score_total': candidates[3]['score_total'] if len(candidates) > 3 else 0.0,\n",
    "\n",
    "                    # Top 5 ÌõÑÎ≥¥\n",
    "                    'top5_drug_id': candidates[4]['drug_id'] if len(candidates) > 4 else '',\n",
    "                    'top5_drug_name': candidates[4]['dl_name'] if len(candidates) > 4 else '',\n",
    "                    'top5_score_total': candidates[4]['score_total'] if len(candidates) > 4 else 0.0,\n",
    "\n",
    "                    # Top 6 ÌõÑÎ≥¥\n",
    "                    'top6_drug_id': candidates[5]['drug_id'] if len(candidates) > 5 else '',\n",
    "                    'top6_drug_name': candidates[5]['dl_name'] if len(candidates) > 5 else '',\n",
    "                    'top6_score_total': candidates[5]['score_total'] if len(candidates) > 5 else 0.0,\n",
    "\n",
    "                    # Top 7 ÌõÑÎ≥¥\n",
    "                    'top7_drug_id': candidates[6]['drug_id'] if len(candidates) > 6 else '',\n",
    "                    'top7_drug_name': candidates[6]['dl_name'] if len(candidates) > 6 else '',\n",
    "                    'top7_score_total': candidates[6]['score_total'] if len(candidates) > 6 else 0.0,\n",
    "\n",
    "                    # Top 8 ÌõÑÎ≥¥\n",
    "                    'top8_drug_id': candidates[7]['drug_id'] if len(candidates) > 7 else '',\n",
    "                    'top8_drug_name': candidates[7]['dl_name'] if len(candidates) > 7 else '',\n",
    "                    'top8_score_total': candidates[7]['score_total'] if len(candidates) > 7 else 0.0,\n",
    "\n",
    "                    # Top 9 ÌõÑÎ≥¥\n",
    "                    'top9_drug_id': candidates[8]['drug_id'] if len(candidates) > 8 else '',\n",
    "                    'top9_drug_name': candidates[8]['dl_name'] if len(candidates) > 8 else '',\n",
    "                    'top9_score_total': candidates[8]['score_total'] if len(candidates) > 8 else 0.0,\n",
    "\n",
    "                    # Ï†ïÎãµ Ïó¨Î∂Ä (Î©îÌä∏Î¶≠)\n",
    "                    'hit_top1': hit_top1,\n",
    "                    'hit_top3': hit_top3,\n",
    "                    'hit_top5': hit_top5,\n",
    "                    'hit_top9': hit_top9,\n",
    "                }\n",
    "\n",
    "                results_list.append(record)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\n Ïò§Î•ò Î∞úÏÉù ({img_path}): {e}\")\n",
    "            continue\n",
    "\n",
    "    df_results = pd.DataFrame(results_list)\n",
    "\n",
    "    df_results.to_csv(OUTPUT_CSV, index=False, encoding='utf-8-sig')\n",
    "    print(f\"\\nÍ≤∞Í≥º Ï†ÄÏû• ÏôÑÎ£å: {OUTPUT_CSV}\")\n",
    "\n",
    "    return df_results\n"
   ],
   "outputs": [],
   "execution_count": 108
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T01:45:56.287222Z",
     "start_time": "2025-12-12T01:45:56.281731Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_metrics(df_results):\n",
    "    \"\"\"Top-1, Top-3, Top-5, Top-9 Accuracy Í≥ÑÏÇ∞\"\"\"\n",
    "\n",
    "    total = len(df_results)\n",
    "\n",
    "    top1_acc = df_results['hit_top1'].sum() / total * 100\n",
    "    top3_acc = df_results['hit_top3'].sum() / total * 100\n",
    "    top5_acc = df_results['hit_top5'].sum() / total * 100\n",
    "    top9_acc = df_results['hit_top9'].sum() / total * 100\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"> Ï†ÑÏ≤¥ ÌèâÍ∞Ä Í≤∞Í≥º\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Ï¥ù Í≤ÄÏ∂úÎêú ÏïΩ: {total}Í∞ú\")\n",
    "    print(f\"\\n > Ï†ïÌôïÎèÑ Î©îÌä∏Î¶≠:\")\n",
    "    print(f\"  ‚Ä¢ Top-1 Accuracy: {top1_acc:.2f}% ({df_results['hit_top1'].sum()}/{total})\")\n",
    "    print(f\"  ‚Ä¢ Top-3 Accuracy: {top3_acc:.2f}% ({df_results['hit_top3'].sum()}/{total})\")\n",
    "    print(f\"  ‚Ä¢ Top-5 Accuracy: {top5_acc:.2f}% ({df_results['hit_top5'].sum()}/{total})\")\n",
    "    print(f\"  ‚Ä¢ Top-9 Accuracy: {top9_acc:.2f}% ({df_results['hit_top9'].sum()}/{total})\")\n",
    "\n",
    "    # ÌèâÍ∑† Ïä§ÏΩîÏñ¥\n",
    "    print(f\"\\n- ÌèâÍ∑† ÏòàÏ∏° Ï†êÏàò:\")\n",
    "    print(f\"  ‚Ä¢ Ï¥ùÏ†ê: {df_results['top1_score_total'].mean():.3f}\")\n",
    "    print(f\"  ‚Ä¢ Í∞ÅÏù∏: {df_results['top1_score_engraving'].mean():.3f}\")\n",
    "    print(f\"  ‚Ä¢ ÏÉâÏÉÅ: {df_results['top1_score_color'].mean():.3f}\")\n",
    "    print(f\"  ‚Ä¢ Î™®Ïñë: {df_results['top1_score_shape'].mean():.3f}\")\n",
    "    print(f\"  ‚Ä¢ Î∂ÑÌï†ÏÑ†: {df_results['top1_score_line'].mean():.3f}\")\n",
    "\n",
    "    # OCR Ïã†Î¢∞ÎèÑ\n",
    "    print(f\"\\n- ÌèâÍ∑† OCR Ïã†Î¢∞ÎèÑ: {df_results['ocr_confidence'].mean():.3f}\")\n",
    "\n",
    "    return {\n",
    "        'total': total,\n",
    "        'top1_accuracy': top1_acc,\n",
    "        'top3_accuracy': top3_acc,\n",
    "        'top5_accuracy': top5_acc,\n",
    "        'top9_accuracy': top9_acc,\n",
    "    }"
   ],
   "outputs": [],
   "execution_count": 109
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-12-12T01:45:56.295201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Ïã§Ìñâ\n",
    "df_results = evaluate_all_images()\n",
    "metrics = calculate_metrics(df_results)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Ïã§Ìå® ÏºÄÏù¥Ïä§ ÏÉòÌîå (Top-1 ÎØ∏Ïä§)\")\n",
    "print(f\"{'='*70}\")\n",
    "failures = df_results[~df_results['hit_top1']].head(10)\n",
    "for idx, row in failures.iterrows():\n",
    "    print(f\"\\nÌååÏùº: {row['filename']}\")\n",
    "    print(f\"  Ï†ïÎãµ: {row['target_ids']}\")\n",
    "    print(f\"  ÏòàÏ∏°: {row['top1_drug_id']} ({row['top1_drug_name']})\")\n",
    "    print(f\"  Ï†êÏàò: {row['top1_score_total']:.3f}\")\n",
    "    print(f\"  Í∞ÅÏù∏: '{row['pred_engraving']}' (conf={row['ocr_confidence']:.2f})\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Î™®Îì† Ï≤òÎ¶¨ ÏôÑÎ£å!\")\n",
    "print(f\"{'='*70}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ï¥ù 484Í∞ú Ïù¥ÎØ∏ÏßÄ Î∞úÍ≤¨\n",
      "Ïù¥ Ï§ë ÎûúÎç§ 10Í∞úÎßå ÏÑ†ÌÉùÌï¥ÏÑú ÌèâÍ∞ÄÌï©ÎãàÎã§.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Ïù¥ÎØ∏ÏßÄ Ï≤òÎ¶¨ Ï§ë:   0%|          | 0/10 [00:00<?, ?it/s]\u001B[A\n",
      "Ïù¥ÎØ∏ÏßÄ Ï≤òÎ¶¨ Ï§ë:  10%|‚ñà         | 1/10 [00:25<03:45, 25.05s/it]\u001B[A"
     ]
    }
   ],
   "execution_count": null
  }
 ]
}
